{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a0be18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\shinras\\anaconda3\\envs\\tf_wbc\\lib\\site-packages (22.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395fd38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (209549, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_path = r\"C:\\Users\\ShinraS\\Desktop\\Projet_Challenge_BPI\"\n",
    "\n",
    "models_path = os.path.join(base_path, \"models\")\n",
    "\n",
    "X_train = np.load(os.path.join(base_path, 'X_train.npy'))\n",
    "y_act_train = np.load(os.path.join(base_path, 'y_act_train.npy'))\n",
    "y_time_train = np.load(os.path.join(base_path, 'y_time_train.npy'))\n",
    "\n",
    "X_test = np.load(os.path.join(models_path, 'X_test.npy'))\n",
    "\n",
    "y_act_test = np.load(os.path.join(base_path, 'y_act_test.npy'))\n",
    "y_time_test = np.load(os.path.join(base_path, 'y_time_test.npy'))\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0af4775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entraînement du modèle Mono-Activité\n",
      "Epoch 1/15\n",
      "5220/5220 [==============================] - 18s 3ms/step - loss: 0.7523 - accuracy: 0.7702 - val_loss: 0.4506 - val_accuracy: 0.8542\n",
      "Epoch 2/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.4706 - accuracy: 0.8491 - val_loss: 0.4206 - val_accuracy: 0.8578\n",
      "Epoch 3/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.4391 - accuracy: 0.8560 - val_loss: 0.3963 - val_accuracy: 0.8646\n",
      "Epoch 4/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.4207 - accuracy: 0.8597 - val_loss: 0.3848 - val_accuracy: 0.8685\n",
      "Epoch 5/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.4108 - accuracy: 0.8622 - val_loss: 0.3797 - val_accuracy: 0.8696\n",
      "Epoch 6/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.4035 - accuracy: 0.8641 - val_loss: 0.3781 - val_accuracy: 0.8681\n",
      "Epoch 7/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.3984 - accuracy: 0.8651 - val_loss: 0.3749 - val_accuracy: 0.8702\n",
      "Epoch 8/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.3938 - accuracy: 0.8660 - val_loss: 0.3832 - val_accuracy: 0.8686\n",
      "Epoch 9/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.3906 - accuracy: 0.8663 - val_loss: 0.3720 - val_accuracy: 0.8705\n",
      "Epoch 10/15\n",
      "5220/5220 [==============================] - 18s 3ms/step - loss: 0.3877 - accuracy: 0.8671 - val_loss: 0.3674 - val_accuracy: 0.8720\n",
      "Epoch 11/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.3847 - accuracy: 0.8677 - val_loss: 0.3658 - val_accuracy: 0.8717\n",
      "Epoch 12/15\n",
      "5220/5220 [==============================] - 18s 3ms/step - loss: 0.3826 - accuracy: 0.8679 - val_loss: 0.3628 - val_accuracy: 0.8730\n",
      "Epoch 13/15\n",
      "5220/5220 [==============================] - 18s 3ms/step - loss: 0.3807 - accuracy: 0.8683 - val_loss: 0.3627 - val_accuracy: 0.8725\n",
      "Epoch 14/15\n",
      "5220/5220 [==============================] - 18s 3ms/step - loss: 0.3790 - accuracy: 0.8689 - val_loss: 0.3612 - val_accuracy: 0.8733\n",
      "Epoch 15/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.3774 - accuracy: 0.8691 - val_loss: 0.3608 - val_accuracy: 0.8739\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_timesteps = X_train.shape[1] \n",
    "n_features = X_train.shape[2]  \n",
    "\n",
    "num_classes = int(np.max(y_act_train) + 1) \n",
    "\n",
    "\n",
    "inputs_mono = Input(shape=(n_timesteps, n_features))\n",
    "x = LSTM(64, return_sequences=False)(inputs_mono)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output_act = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_mono_act = Model(inputs=inputs_mono, outputs=output_act)\n",
    "\n",
    "model_mono_act.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "print(\" Entraînement du modèle Mono-Activité\")\n",
    "history_act = model_mono_act.fit(\n",
    "    X_train, y_act_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=15, \n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dbc8942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle Mono-Temps\n",
      "Epoch 1/15\n",
      "5220/5220 [==============================] - 19s 3ms/step - loss: 0.0176 - mae: 0.0771 - val_loss: 0.0119 - val_mae: 0.0530\n",
      "Epoch 2/15\n",
      "5220/5220 [==============================] - 18s 3ms/step - loss: 0.0116 - mae: 0.0547 - val_loss: 0.0101 - val_mae: 0.0475\n",
      "Epoch 3/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.0106 - mae: 0.0501 - val_loss: 0.0097 - val_mae: 0.0475\n",
      "Epoch 4/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.0103 - mae: 0.0485 - val_loss: 0.0097 - val_mae: 0.0453\n",
      "Epoch 5/15\n",
      "5220/5220 [==============================] - 16s 3ms/step - loss: 0.0101 - mae: 0.0473 - val_loss: 0.0095 - val_mae: 0.0447\n",
      "Epoch 6/15\n",
      "5220/5220 [==============================] - 16s 3ms/step - loss: 0.0100 - mae: 0.0467 - val_loss: 0.0095 - val_mae: 0.0445\n",
      "Epoch 7/15\n",
      "5220/5220 [==============================] - 16s 3ms/step - loss: 0.0098 - mae: 0.0461 - val_loss: 0.0094 - val_mae: 0.0443\n",
      "Epoch 8/15\n",
      "5220/5220 [==============================] - 16s 3ms/step - loss: 0.0098 - mae: 0.0457 - val_loss: 0.0093 - val_mae: 0.0433\n",
      "Epoch 9/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.0097 - mae: 0.0454 - val_loss: 0.0095 - val_mae: 0.0429\n",
      "Epoch 10/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.0096 - mae: 0.0451 - val_loss: 0.0093 - val_mae: 0.0436\n",
      "Epoch 11/15\n",
      "5220/5220 [==============================] - 18s 3ms/step - loss: 0.0096 - mae: 0.0448 - val_loss: 0.0092 - val_mae: 0.0406\n",
      "Epoch 12/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.0095 - mae: 0.0446 - val_loss: 0.0093 - val_mae: 0.0429\n",
      "Epoch 13/15\n",
      "5220/5220 [==============================] - 17s 3ms/step - loss: 0.0095 - mae: 0.0444 - val_loss: 0.0092 - val_mae: 0.0424\n",
      "Epoch 14/15\n",
      "5220/5220 [==============================] - 16s 3ms/step - loss: 0.0095 - mae: 0.0443 - val_loss: 0.0093 - val_mae: 0.0431\n",
      "Epoch 15/15\n",
      "5220/5220 [==============================] - 16s 3ms/step - loss: 0.0095 - mae: 0.0442 - val_loss: 0.0092 - val_mae: 0.0429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs_time = Input(shape=(n_timesteps, n_features))\n",
    "x = LSTM(64, return_sequences=False)(inputs_time)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output_time = Dense(1, activation='linear')(x) \n",
    "model_mono_time = Model(inputs=inputs_time, outputs=output_time)\n",
    "\n",
    "model_mono_time.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',    \n",
    "    metrics=['mae']  \n",
    ")\n",
    "\n",
    "\n",
    "print(\"Entraînement du modèle Mono-Temps\")\n",
    "history_time = model_mono_time.fit(\n",
    "    X_train, y_time_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30939c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle Multi-Task\n",
      "Epoch 1/15\n",
      "5220/5220 [==============================] - 40s 7ms/step - loss: 0.6752 - act_output_loss: 0.6523 - time_output_loss: 0.0229 - act_output_accuracy: 0.8013 - time_output_mae: 0.1044 - val_loss: 0.4231 - val_act_output_loss: 0.4082 - val_time_output_loss: 0.0149 - val_act_output_accuracy: 0.8622 - val_time_output_mae: 0.0731\n",
      "Epoch 2/15\n",
      "5220/5220 [==============================] - 37s 7ms/step - loss: 0.4432 - act_output_loss: 0.4264 - time_output_loss: 0.0168 - act_output_accuracy: 0.8601 - time_output_mae: 0.0848 - val_loss: 0.3952 - val_act_output_loss: 0.3820 - val_time_output_loss: 0.0132 - val_act_output_accuracy: 0.8688 - val_time_output_mae: 0.0677\n",
      "Epoch 3/15\n",
      "5220/5220 [==============================] - 38s 7ms/step - loss: 0.4189 - act_output_loss: 0.4031 - time_output_loss: 0.0158 - act_output_accuracy: 0.8647 - time_output_mae: 0.0798 - val_loss: 0.3861 - val_act_output_loss: 0.3732 - val_time_output_loss: 0.0129 - val_act_output_accuracy: 0.8708 - val_time_output_mae: 0.0644\n",
      "Epoch 4/15\n",
      "5220/5220 [==============================] - 38s 7ms/step - loss: 0.4079 - act_output_loss: 0.3929 - time_output_loss: 0.0150 - act_output_accuracy: 0.8667 - time_output_mae: 0.0753 - val_loss: 0.3840 - val_act_output_loss: 0.3716 - val_time_output_loss: 0.0125 - val_act_output_accuracy: 0.8703 - val_time_output_mae: 0.0647\n",
      "Epoch 5/15\n",
      "5220/5220 [==============================] - 37s 7ms/step - loss: 0.4002 - act_output_loss: 0.3857 - time_output_loss: 0.0145 - act_output_accuracy: 0.8680 - time_output_mae: 0.0728 - val_loss: 0.3751 - val_act_output_loss: 0.3628 - val_time_output_loss: 0.0123 - val_act_output_accuracy: 0.8725 - val_time_output_mae: 0.0594\n",
      "Epoch 6/15\n",
      "5220/5220 [==============================] - 37s 7ms/step - loss: 0.3949 - act_output_loss: 0.3806 - time_output_loss: 0.0143 - act_output_accuracy: 0.8689 - time_output_mae: 0.0714 - val_loss: 0.3712 - val_act_output_loss: 0.3594 - val_time_output_loss: 0.0118 - val_act_output_accuracy: 0.8735 - val_time_output_mae: 0.0589\n",
      "Epoch 7/15\n",
      "5220/5220 [==============================] - 37s 7ms/step - loss: 0.3904 - act_output_loss: 0.3763 - time_output_loss: 0.0141 - act_output_accuracy: 0.8700 - time_output_mae: 0.0708 - val_loss: 0.3717 - val_act_output_loss: 0.3600 - val_time_output_loss: 0.0117 - val_act_output_accuracy: 0.8731 - val_time_output_mae: 0.0599\n",
      "Epoch 8/15\n",
      "5220/5220 [==============================] - 38s 7ms/step - loss: 0.3861 - act_output_loss: 0.3722 - time_output_loss: 0.0139 - act_output_accuracy: 0.8715 - time_output_mae: 0.0700 - val_loss: 0.3671 - val_act_output_loss: 0.3551 - val_time_output_loss: 0.0120 - val_act_output_accuracy: 0.8760 - val_time_output_mae: 0.0601\n",
      "Epoch 9/15\n",
      "5220/5220 [==============================] - 38s 7ms/step - loss: 0.3829 - act_output_loss: 0.3691 - time_output_loss: 0.0138 - act_output_accuracy: 0.8727 - time_output_mae: 0.0695 - val_loss: 0.3634 - val_act_output_loss: 0.3521 - val_time_output_loss: 0.0113 - val_act_output_accuracy: 0.8757 - val_time_output_mae: 0.0576\n",
      "Epoch 10/15\n",
      "5220/5220 [==============================] - 39s 7ms/step - loss: 0.3795 - act_output_loss: 0.3659 - time_output_loss: 0.0136 - act_output_accuracy: 0.8739 - time_output_mae: 0.0689 - val_loss: 0.3618 - val_act_output_loss: 0.3500 - val_time_output_loss: 0.0117 - val_act_output_accuracy: 0.8784 - val_time_output_mae: 0.0574\n",
      "Epoch 11/15\n",
      "5220/5220 [==============================] - 37s 7ms/step - loss: 0.3774 - act_output_loss: 0.3639 - time_output_loss: 0.0135 - act_output_accuracy: 0.8746 - time_output_mae: 0.0685 - val_loss: 0.3626 - val_act_output_loss: 0.3514 - val_time_output_loss: 0.0112 - val_act_output_accuracy: 0.8771 - val_time_output_mae: 0.0557\n",
      "Epoch 12/15\n",
      "5220/5220 [==============================] - 37s 7ms/step - loss: 0.3758 - act_output_loss: 0.3625 - time_output_loss: 0.0134 - act_output_accuracy: 0.8750 - time_output_mae: 0.0681 - val_loss: 0.3595 - val_act_output_loss: 0.3477 - val_time_output_loss: 0.0117 - val_act_output_accuracy: 0.8785 - val_time_output_mae: 0.0629\n",
      "Epoch 13/15\n",
      "5220/5220 [==============================] - 38s 7ms/step - loss: 0.3746 - act_output_loss: 0.3614 - time_output_loss: 0.0132 - act_output_accuracy: 0.8755 - time_output_mae: 0.0674 - val_loss: 0.3595 - val_act_output_loss: 0.3476 - val_time_output_loss: 0.0118 - val_act_output_accuracy: 0.8789 - val_time_output_mae: 0.0578\n",
      "Epoch 14/15\n",
      "5220/5220 [==============================] - 37s 7ms/step - loss: 0.3724 - act_output_loss: 0.3594 - time_output_loss: 0.0130 - act_output_accuracy: 0.8759 - time_output_mae: 0.0667 - val_loss: 0.3562 - val_act_output_loss: 0.3456 - val_time_output_loss: 0.0107 - val_act_output_accuracy: 0.8782 - val_time_output_mae: 0.0567\n",
      "Epoch 15/15\n",
      "5220/5220 [==============================] - 37s 7ms/step - loss: 0.3711 - act_output_loss: 0.3583 - time_output_loss: 0.0128 - act_output_accuracy: 0.8762 - time_output_mae: 0.0660 - val_loss: 0.3555 - val_act_output_loss: 0.3445 - val_time_output_loss: 0.0110 - val_act_output_accuracy: 0.8790 - val_time_output_mae: 0.0557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs_multi = Input(shape=(n_timesteps, n_features))\n",
    "\n",
    "\n",
    "shared_lstm = LSTM(128, return_sequences=False)(inputs_multi)\n",
    "shared_dense = Dense(64, activation='relu')(shared_lstm)\n",
    "shared_dropout = Dropout(0.2)(shared_dense)\n",
    "\n",
    "# Sortie A : Activité (Classification)\n",
    "output_act = Dense(num_classes, activation='softmax', name='act_output')(shared_dropout)\n",
    "\n",
    "# Sortie B : Temps (Régression)\n",
    "output_time = Dense(1, activation='linear', name='time_output')(shared_dropout)\n",
    "\n",
    "model_multi = Model(inputs=inputs_multi, outputs=[output_act, output_time])\n",
    "\n",
    "model_multi.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'act_output': 'sparse_categorical_crossentropy', 'time_output': 'mse'},\n",
    "    loss_weights={'act_output': 1.0, 'time_output': 1.0}, \n",
    "    metrics={'act_output': 'accuracy', 'time_output': 'mae'}\n",
    ")\n",
    "\n",
    "print(\"Entraînement du modèle Multi-Task\")\n",
    "history_multi = model_multi.fit(\n",
    "    X_train, \n",
    "    {'act_output': y_act_train, 'time_output': y_time_train}, \n",
    "    validation_split=0.2,\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6061aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'le_act' est prêt avec 26 classes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "all_indices = np.arange(26)\n",
    "\n",
    "le_act = LabelEncoder()\n",
    "placeholder_names = [f\"Activity_{i}\" for i in range(26)]\n",
    "le_act.fit(placeholder_names)\n",
    "\n",
    "scaler_time = MinMaxScaler()\n",
    "scaler_time.fit(np.array([0, 15]).reshape(-1, 1)) \n",
    "\n",
    "print(\"'le_act' est prêt avec 26 classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa285357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ShinraS\\anaconda3\\envs\\tf_wbc\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.7.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6549/6549 [==============================] - 9s 1ms/step\n",
      "Taux d'alerte : 9.28%\n",
      "   Activite_Predite_Index  Delais_Heures_Predits  Est_Goulot\n",
      "0                       3              -0.044982       False\n",
      "1                      21              24.637098        True\n",
      "2                      12              -0.081590       False\n",
      "3                      13              -0.147051       False\n",
      "4                      16               0.104082       False\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "path_scaler = os.path.join(\"..\", \"models\", \"scaler_time.joblib\")\n",
    "scaler_time = joblib.load(path_scaler)\n",
    "path_model = os.path.join(\"..\", \"models\", \"model_multi_task.keras\")\n",
    "model = tf.keras.models.load_model(path_model)\n",
    "preds_act, preds_time_norm = model.predict(X_test)\n",
    "pred_act_idx = np.argmax(preds_act, axis=1)\n",
    "pred_act_names = [f\"Act_{i}\" for i in pred_act_idx] \n",
    "\n",
    "preds_time_log = scaler_time.inverse_transform(preds_time_norm.reshape(-1, 1))\n",
    "preds_time_hours = np.expm1(preds_time_log).flatten()\n",
    "\n",
    "import pandas as pd\n",
    "analysis_df = pd.DataFrame({\n",
    "    'Activite_Predite_Index': pred_act_idx,\n",
    "    'Delais_Heures_Predits': preds_time_hours\n",
    "})\n",
    "\n",
    "SEUIL_CRITIQUE = 21.0\n",
    "analysis_df['Est_Goulot'] = analysis_df['Delais_Heures_Predits'] > SEUIL_CRITIQUE\n",
    "taux_alerte = analysis_df['Est_Goulot'].mean() * 100\n",
    "print(f\"Taux d'alerte : {taux_alerte:.2f}%\")\n",
    "print(analysis_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a282a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "le_act = joblib.load('../models/le_act.joblib')\n",
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models')\n",
    "model.save('../models/model_multi_task.keras')\n",
    "joblib.dump(le_act, '../models/le_act.joblib')\n",
    "joblib.dump(scaler_time, '../models/scaler_time.joblib')\n",
    "np.save('../models/X_test.npy', X_test)\n",
    "\n",
    "print(\"All saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_wbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
