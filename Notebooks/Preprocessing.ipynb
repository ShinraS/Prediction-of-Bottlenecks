{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9baaee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Génération des séquences enrichies...\n",
      " Preprocessing terminé !\n",
      "Structure de X_train : (835173, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "df = pd.read_parquet(\"../bpi_2017_cleaned.parquet\")\n",
    "\n",
    "le_act = LabelEncoder()\n",
    "le_type = LabelEncoder()\n",
    "\n",
    "df['act_num'] = le_act.fit_transform(df['concept:name'])\n",
    "df['is_new_credit'] = le_type.fit_transform(df['case:ApplicationType'])\n",
    "df['weekday'] = df['time:timestamp'].dt.weekday\n",
    "df['event_index'] = df.groupby('case:concept:name').cumcount()\n",
    "\n",
    "df['time_log'] = np.log1p(df['time_delta'])\n",
    "scaler_time = MinMaxScaler()\n",
    "df['time_norm'] = scaler_time.fit_transform(df[['time_log']])\n",
    "\n",
    "scaler_index = MinMaxScaler()\n",
    "df['event_index_norm'] = scaler_index.fit_transform(df[['event_index']])\n",
    "\n",
    "case_starts = df[df['concept:name'] == 'A_Create Application'].sort_values('time:timestamp')\n",
    "unique_cases = case_starts['case:concept:name'].values\n",
    "\n",
    "split_idx = int(len(unique_cases) * 0.8)\n",
    "train_cases = unique_cases[:split_idx]\n",
    "test_cases = unique_cases[split_idx:]\n",
    "\n",
    "def create_sequences_enriched(case_list, dataframe, window_size=5):\n",
    "    X, y_act, y_time = [], [], []\n",
    "    subset = dataframe[dataframe['case:concept:name'].isin(case_list)]\n",
    "    grouped = subset.groupby('case:concept:name')\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        group = group.sort_values('time:timestamp')\n",
    "        \n",
    "        acts = group['act_num'].values\n",
    "        types = group['is_new_credit'].values\n",
    "        days = group['weekday'].values\n",
    "        idxs = group['event_index_norm'].values\n",
    "        times = group['time_norm'].values\n",
    "        \n",
    "        if len(acts) > window_size:\n",
    "            for i in range(window_size, len(acts)):\n",
    "               \n",
    "                window_data = []\n",
    "                for j in range(i-window_size, i):\n",
    "                    window_data.append([acts[j], types[j], days[j], idxs[j]])\n",
    "                \n",
    "                X.append(window_data)\n",
    "                y_act.append(acts[i])\n",
    "                y_time.append(times[i])\n",
    "                \n",
    "    return np.array(X), np.array(y_act), np.array(y_time)\n",
    "\n",
    "print(\" Génération des séquences enrichies...\")\n",
    "X_train, y_act_train, y_time_train = create_sequences_enriched(train_cases, df)\n",
    "X_test, y_act_test, y_time_test = create_sequences_enriched(test_cases, df)\n",
    "\n",
    "print(f\" Preprocessing terminé !\")\n",
    "print(f\"Structure de X_train : {X_train.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f41563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toutes les matrices ont été sauvegardées\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = \"C:\\\\Users\\\\ShinraS\\\\Desktop\\\\Projet_Challenge_BPI\"\n",
    "\n",
    "# Sauvegarde des données d'entraînement\n",
    "np.save(path + 'X_train.npy', X_train)\n",
    "np.save(path + 'y_act_train.npy', y_act_train)\n",
    "np.save(path + 'y_time_train.npy', y_time_train)\n",
    "\n",
    "# Sauvegarde des données de test\n",
    "np.save(path + 'X_test.npy', X_test)\n",
    "np.save(path + 'y_act_test.npy', y_act_test)\n",
    "np.save(path + 'y_time_test.npy', y_time_test)\n",
    "\n",
    "print(\"Toutes les matrices ont été sauvegardées\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c775b0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Décodeur 'le_act' et 'scaler_time' sauvegardés !\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(le_act, path + 'le_act.joblib')\n",
    "joblib.dump(scaler_time, path + 'scaler_time.joblib')\n",
    "\n",
    "print(\"Décodeur 'le_act' et 'scaler_time' sauvegardés !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_wbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
